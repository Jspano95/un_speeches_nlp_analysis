{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1359715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_theme()\n",
    "import regex as re \n",
    "# import random\n",
    "from collections import Counter\n",
    "import pprint as pp\n",
    "from see import see \n",
    "import nltk\n",
    "# conda install -c conda-forge wordcloud\n",
    "# from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d10d21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804b9b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickled DF from notebook #1 (initial exploratory data visuals)\n",
    "df = pd.read_pickle('df_un_general_debates.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8c470e",
   "metadata": {},
   "source": [
    "==X== \n",
    "* ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0aaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18d31011",
   "metadata": {},
   "source": [
    "* Due to the nature of the content, each country is allowed to only deliver a single speech each year\n",
    "    * Thus, it is quite likely that different paragraphs within the speeches are separated by paragraphs\n",
    "    * Accordingly, these paragraphs quite likely have different topics\n",
    "    \n",
    "* Also raises the issue of formatting issues with how do we define beginning, ends etc. of paragraphs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79eb3d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33: May I first convey to our President the congratulations of the Albanian delegation on his election to the Presidency of the twenty-fifth session of the General Assembly?\\n34.\\tIn taking up the work on the agenda of the twenty- fifth session of the General Assembly, which is being held on the eve of the twenty-fifth anniversary of the coming into force of the Charter of the United Nations, the peace-loving Member States would have wished to be in a position to present on this occasion some pict'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's recall the same example from notebook #2\n",
    "# example 1 \n",
    "df.iloc[0]['text'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac23a7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ufeffOn behalf of the State of Kuwait, it\\ngives me pleasure to congratulate Mr. Han Seung-soo,\\nand his friendly country, the Republic of Korea, on his\\nelection as President of the fifty-sixth session of t'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. #2\n",
    "df.iloc[4729][\"text\"][0:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc9130c",
   "metadata": {},
   "source": [
    "* There are newline characters being used to separate prargraphs in the first example\n",
    "* But in the 2nd example below, newline characters used to separate lines\n",
    "\n",
    "#### Thus, we need another method to discern the paragraphs \n",
    "* E.G. try splitting at stops, exclamation marks, question marks etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdbf9a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\s* = zero or more whitespace chars \n",
    "\n",
    "# define the number of paragraphs of the text, splitting on the punctuation and ignoring the whitespace after them\n",
    "df[\"paragraphs\"] = df[\"text\"].map(lambda text: re.split('[.?!]\\s*\\n', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0d6efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of paragraphs by country by mapping the len function\n",
    "df[\"number_of_paragraphs\"] = df[\"paragraphs\"].map(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa0372bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>country_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>position</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokens</th>\n",
       "      <th>len_tokens</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>number_of_paragraphs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>ALB</td>\n",
       "      <td>Albania</td>\n",
       "      <td>Mr. NAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33: May I first convey to our President the co...</td>\n",
       "      <td>51419</td>\n",
       "      <td>[may, first, convey, president, congratulation...</td>\n",
       "      <td>4125</td>\n",
       "      <td>[33: May I first convey to our President the c...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>1970</td>\n",
       "      <td>ARG</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Mr. DE PABLO PARDO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.\\t : It is a fortunate coincidence that pr...</td>\n",
       "      <td>29286</td>\n",
       "      <td>[fortunate, coincidence, precisely, time, unit...</td>\n",
       "      <td>2327</td>\n",
       "      <td>[177.\\t : It is a fortunate coincidence that p...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session  year country country_name             speaker position  \\\n",
       "0       25  1970     ALB      Albania             Mr. NAS      NaN   \n",
       "1       25  1970     ARG    Argentina  Mr. DE PABLO PARDO      NaN   \n",
       "\n",
       "                                                text  length  \\\n",
       "0  33: May I first convey to our President the co...   51419   \n",
       "1  177.\\t : It is a fortunate coincidence that pr...   29286   \n",
       "\n",
       "                                              tokens  len_tokens  \\\n",
       "0  [may, first, convey, president, congratulation...        4125   \n",
       "1  [fortunate, coincidence, precisely, time, unit...        2327   \n",
       "\n",
       "                                          paragraphs  number_of_paragraphs  \n",
       "0  [33: May I first convey to our President the c...                    60  \n",
       "1  [177.\\t : It is a fortunate coincidence that p...                    50  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.G. \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5c8e941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for curiosity, does the number of paragraphs change over time?\n",
    "## as we noted before, avg words had decreased as num_countries went up -- so we somewhat expect the same\n",
    "df.groupby('year')['number_of_paragraphs'].mean().plot.bar(figsize=(14,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94944d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6555a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1e68eed",
   "metadata": {},
   "source": [
    "## TOPIC MODELING PREPARATIONS\n",
    "* Start with document-term matrix\n",
    "    * matrix with elements as word frequencies (often tf-idf scaled weights)\n",
    "        * of the words (columns) in the corresponding documents (rows)\n",
    "    * The matrix is sparse, as most docs contain only a fraction of the total vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a90dfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-construct stopwords with additional corpus-specific elements (from notebook #2) to pass into tfidf_vectoriser \n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07d61d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make manual adjustments \n",
    "additional_stopwords = {'dear','regards','also','would','must'}\n",
    "exclude_stopwords = {'against'}\n",
    "\n",
    "# user set operators to add or remove these elements from our base collection\n",
    "stopwords |= additional_stopwords\n",
    "\n",
    "## use the set difference to remove these words \n",
    "stopwords -= exclude_stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ae12a5",
   "metadata": {},
   "source": [
    "### TF-IDF VECTORISER\n",
    "* `min_df` = when building vocab, ignore terms with a document fequency lower than this threshold (AKA cut-off value)\n",
    "    * this value represents proportion of documents if float between (0.0, 1.0)\n",
    "    * Else, absolute counts if integer \n",
    "* `max_df` = the inverse, ignore terms with highr than this threshold (akin to: corpus specific stop-words)\n",
    "    * same rules apply for float/integer \n",
    "* `smooth_idf` = adding 1 to document term frequencies (same as notebook #2) \n",
    "* `ngram_range` = different n-grams extraction:\n",
    "    * (1, 1) = only unigrams\n",
    "    * (1, 2) = unigrams and bigrams\n",
    "    * (2, 2) = only bigrams etc. \n",
    "    \n",
    "    \n",
    "    \n",
    "#### First iteration: start with just uni-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8571c6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf-idf vectoriser for speech's text: ##\n",
    "\n",
    "## start with just unigrams \n",
    "tfidf_text_vectorizer_unigrams = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7, smooth_idf = True, \n",
    "                                       ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c718e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## with bigrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a32a492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7507, 340767)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9e989d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tfidf_text_vectors = tfidf_text_vectorizer_unigrams.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac591dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7507, 24747)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd556180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c087713",
   "metadata": {},
   "source": [
    "#### Repeat for the paragraphs \n",
    "* slightly more challenging, must \"flatten\" each praragraph to it's own row + keep the right reference to its respective year \n",
    "* empty paragraphs are omitted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5821ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to keep the country variable too\n",
    "## perhaps test in subsequent iteration \n",
    "\"\"\" \n",
    "paragraph_df_by_country = pd.DataFrame([{ \"text\": paragraph, \"year\": year, \"country\": country} \n",
    "                               for paragraphs, year, country in zip(df[\"paragraphs\"], df[\"year\"], df[\"country\"]) \n",
    "                                    for paragraph in paragraphs if paragraph])\n",
    "                        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eafa2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_df = pd.DataFrame([{ \"text\": paragraph, \"year\": year } \n",
    "                               for paragraphs, year in zip(df[\"paragraphs\"], df[\"year\"]) \n",
    "                                    for paragraph in paragraphs if paragraph])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f076e057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287346"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['number_of_paragraphs'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b3134d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282210, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# E.G. can see the length of this DF is roughly equivalent to number_of_paragraphs total (less a few for removing empty ones)\n",
    "paragraph_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e51f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5113ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply tf-idf vectoriser to paragraphs; same min and max params\n",
    "tfidf_para_vectorizer = TfidfVectorizer(stop_words=stopwords, min_df=5, max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d4101f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "tfidf_para_vectors = tfidf_para_vectorizer.fit_transform(paragraph_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "827c22bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282210, 25324)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_para_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c24f7",
   "metadata": {},
   "source": [
    "* NOTE: the number of columns has changed as min_df and max_df have had their scaling effect in selecting features changed slightly as the number of documents is different for paragraphs vs. text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bee5c22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af90b816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71ea85ee",
   "metadata": {},
   "source": [
    "## \n",
    "\n",
    "## Nonnegative Matrix Factorisation (NMF)\n",
    "* the factorisation of the document-term matrix (DTM) \n",
    "    * DTM has only positive elements (can't have a negative count for a word obviously) \n",
    "* Conventional notation:\n",
    "    * original matrix = V\n",
    "    * Factors: W and H\n",
    "        * such that: V $\\approx$ W * H\n",
    "* Matrix W has the same number of rows as DTM and maps documents to topics\n",
    "* H has the same number of columns as features (shows how topics are part of features)\n",
    "* The number of topics (columns of W and the rows of H) can be chosen arbitarily to start with\n",
    "    * The smaller this number, the less exact the factorisation\n",
    "    * The larger the number, the more the factorisation is exact + computationally expensive\n",
    "        * In reality, an approximate factorisation is sufficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b89a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "29fdcc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with an arbitrary 10 topics (can be tuned later)\n",
    "nmf_text_model = NMF(n_components=10, random_state=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0976bc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n",
      "C:\\Users\\jason\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1090: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\"Maximum number of iterations %d reached. Increase it to\"\n"
     ]
    }
   ],
   "source": [
    "# specify (W) matrix by applying nmf model to tfidf of text vectors \n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5d036d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify (H) using the components_ function form the NMF class\n",
    "H_text_matrix = nmf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16c54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5f673d6",
   "metadata": {},
   "source": [
    "### Specify a function for outputing a clean summary\n",
    "* Consider matrix (H) and find the largest values in each topic (row) \n",
    "    * Then, use these as the lookup index \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c1255698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, features, top_words=5):\n",
    "    for topic, word_vector in enumerate(model.components_):\n",
    "\n",
    "        #calculate the sum of the vector so we can later get the % contribution of individual words \n",
    "        total = word_vector.sum()\n",
    "\n",
    "        # invert sort order (put index of largest value first)\n",
    "        largest = word_vector.argsort()[::-1] \n",
    "\n",
    "        # print header \n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "\n",
    "        # loop through top words (# specified number of {})\n",
    "        for i in range(0, top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]],\n",
    "                  word_vector[largest[i]]*100.0/total)) # print contribution/total as %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "299a8128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  co (0.79)\n",
      "  operation (0.65)\n",
      "  disarmament (0.33)\n",
      "  nuclear (0.26)\n",
      "  relations (0.25)\n",
      "  negotiations (0.23)\n",
      "  problem (0.23)\n",
      "  south (0.21)\n",
      "\n",
      "Topic 01\n",
      "  terrorism (0.39)\n",
      "  sustainable (0.35)\n",
      "  challenges (0.34)\n",
      "  climate (0.33)\n",
      "  millennium (0.32)\n",
      "  goals (0.30)\n",
      "  2015 (0.30)\n",
      "  change (0.29)\n",
      "\n",
      "Topic 02\n",
      "  africa (1.14)\n",
      "  african (0.81)\n",
      "  south (0.62)\n",
      "  namibia (0.35)\n",
      "  delegation (0.30)\n",
      "  apartheid (0.28)\n",
      "  oau (0.27)\n",
      "  angola (0.27)\n",
      "\n",
      "Topic 03\n",
      "  arab (1.02)\n",
      "  israel (0.87)\n",
      "  palestinian (0.60)\n",
      "  israeli (0.54)\n",
      "  lebanon (0.54)\n",
      "  iraq (0.46)\n",
      "  resolutions (0.40)\n",
      "  occupation (0.32)\n",
      "\n",
      "Topic 04\n",
      "  american (0.29)\n",
      "  america (0.28)\n",
      "  latin (0.27)\n",
      "  democracy (0.19)\n",
      "  panama (0.18)\n",
      "  bolivia (0.18)\n",
      "  central (0.16)\n",
      "  guatemala (0.15)\n",
      "\n",
      "Topic 05\n",
      "  pacific (1.50)\n",
      "  islands (1.17)\n",
      "  solomon (0.82)\n",
      "  island (0.78)\n",
      "  zealand (0.69)\n",
      "  fiji (0.69)\n",
      "  nuclear (0.53)\n",
      "  small (0.52)\n",
      "\n",
      "Topic 06\n",
      "  soviet (0.81)\n",
      "  republic (0.77)\n",
      "  nuclear (0.69)\n",
      "  socialist (0.62)\n",
      "  viet (0.62)\n",
      "  nam (0.58)\n",
      "  korea (0.52)\n",
      "  struggle (0.45)\n",
      "\n",
      "Topic 07\n",
      "  guinea (4.18)\n",
      "  equatorial (1.72)\n",
      "  bissau (1.50)\n",
      "  papua (1.44)\n",
      "  republic (0.58)\n",
      "  portugal (0.54)\n",
      "  portuguese (0.43)\n",
      "  delegation (0.39)\n",
      "\n",
      "Topic 08\n",
      "  european (0.42)\n",
      "  cooperation (0.40)\n",
      "  europe (0.30)\n",
      "  bosnia (0.25)\n",
      "  nuclear (0.25)\n",
      "  regional (0.22)\n",
      "  herzegovina (0.22)\n",
      "  reform (0.22)\n",
      "\n",
      "Topic 09\n",
      "  caribbean (0.99)\n",
      "  small (0.66)\n",
      "  bahamas (0.65)\n",
      "  saint (0.63)\n",
      "  barbados (0.62)\n",
      "  haiti (0.56)\n",
      "  tobago (0.52)\n",
      "  trinidad (0.50)\n"
     ]
    }
   ],
   "source": [
    "# pass in nmf model to output function \n",
    "## + the tf-idf vectoriser (from text) to get word feature names (aka the word itself) \n",
    "display_topics(nmf_text_model, tfidf_text_vectorizer_unigrams.get_feature_names(),\n",
    "              top_words=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7de3e1",
   "metadata": {},
   "source": [
    "### Brief Overview of Insights:\n",
    "* Topic (0) is interesting, possibly talking about nuclear disarment\n",
    "    * the existence of south, possibly meaning south korea might mean the topic is NK nuclear disarment \n",
    "* Other topics can be quite generalised, representing regions of the world\n",
    "    * E.G topic (3) is clearly focused on the middle-east, including the Israel & Palestinian situation \n",
    "    \n",
    "    \n",
    "    \n",
    "* Important to note that the individual contributions of words is quite small, generally across the board\n",
    "    * Primarily due to the large amount of words\n",
    "* Generally, a topic is well define if the % within a topic is rapidly decreasing\n",
    "    * We can try to tune this later "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c52d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb837daf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebf8b8e4",
   "metadata": {},
   "source": [
    "### we can do a generalised-test to see how many documents are assigned to each topic \n",
    "* a measure of how \"big\" the topics are across the board\n",
    "\n",
    "* can be calculated by: using the DTM & summing the individual topic contributions over all documents\n",
    "    * normalising them with the total sum & conver to percentage \n",
    "    \n",
    "    \n",
    "#### General Indications: \n",
    "* having an even distribution (not having a small amount of massive topics) is a good indicator of good number of topics\n",
    "    * Otherwise, consider adjusting topics up or down accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b3da877f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 = 10.68%\n",
      "Topic 1 = 15.16%\n",
      "Topic 2 = 13.35%\n",
      "Topic 3 = 9.90%\n",
      "Topic 4 = 13.34%\n",
      "Topic 5 = 5.84%\n",
      "Topic 6 = 7.75%\n",
      "Topic 7 = 4.18%\n",
      "Topic 8 = 13.31%\n",
      "Topic 9 = 6.50%\n"
     ]
    }
   ],
   "source": [
    "for i, val in enumerate(W_text_matrix.sum(axis=0) / W_text_matrix.sum() * 100.0 ):\n",
    "    print(\"Topic {} = {:.2f}%\".format(i, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54166220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82b1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f73174",
   "metadata": {},
   "source": [
    "## Re-create the topic models but using paragraphs instead of aggregate speeches\n",
    "* Given the UN speeches have lots of intertwined topics, it can be hard for a top-level modeling algo to find a common topic of an individual speech- particularly in long texts as they perhaps evenly cover a vast amount of topics\n",
    "    * We can account for this by breaking down the speeches into smaller entities (paragraphs) - which makes comparing paragraphs to paragraphs across speeches more cohesive \n",
    "    * It is also logical to assume that 1 paragraph = roughly 1 topic; as is the natural way to conduct a formal speech so we assume this method will be more robust \n",
    "        * We already created this paragraph DF above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a3d7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: from sklearn.decomposition import NMF\n",
    "# repeat steps for text model \n",
    "nmf_para_model = NMF(n_components=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2a91e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jason\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:312: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn((\"The 'init' value, when 'init=None' and \"\n"
     ]
    }
   ],
   "source": [
    "# define matrixes from para model + the afore-defined para vectors variable \n",
    "W_para_matrix = nmf_para_model.fit_transform(tfidf_para_vectors)\n",
    "H_para_matrix = nmf_para_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac60b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "763ecb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  international (1.45)\n",
      "  world (1.33)\n",
      "  community (0.67)\n",
      "  new (0.64)\n",
      "  us (0.58)\n",
      "  peace (0.53)\n",
      "  order (0.44)\n",
      "  problems (0.43)\n",
      "\n",
      "Topic 01\n",
      "  general (2.70)\n",
      "  session (2.69)\n",
      "  assembly (2.65)\n",
      "  mr (1.90)\n",
      "  president (1.72)\n",
      "  election (1.52)\n",
      "  like (1.00)\n",
      "  delegation (0.91)\n",
      "\n",
      "Topic 02\n",
      "  countries (4.22)\n",
      "  developing (2.38)\n",
      "  economic (1.46)\n",
      "  developed (1.29)\n",
      "  trade (0.89)\n",
      "  debt (0.62)\n",
      "  least (0.46)\n",
      "  industrialized (0.46)\n",
      "\n",
      "Topic 03\n",
      "  nations (5.81)\n",
      "  united (5.70)\n",
      "  organization (1.27)\n",
      "  states (1.06)\n",
      "  charter (0.97)\n",
      "  member (0.90)\n",
      "  role (0.85)\n",
      "  secretary (0.55)\n",
      "\n",
      "Topic 04\n",
      "  nuclear (4.83)\n",
      "  weapons (3.20)\n",
      "  disarmament (1.96)\n",
      "  treaty (1.68)\n",
      "  proliferation (1.43)\n",
      "  non (1.20)\n",
      "  arms (1.19)\n",
      "  states (0.91)\n",
      "\n",
      "Topic 05\n",
      "  rights (6.46)\n",
      "  human (6.13)\n",
      "  respect (1.15)\n",
      "  fundamental (0.85)\n",
      "  universal (0.81)\n",
      "  protection (0.79)\n",
      "  democracy (0.66)\n",
      "  declaration (0.64)\n",
      "\n",
      "Topic 06\n",
      "  africa (3.63)\n",
      "  south (3.17)\n",
      "  african (1.62)\n",
      "  namibia (1.33)\n",
      "  apartheid (1.15)\n",
      "  regime (0.83)\n",
      "  people (0.83)\n",
      "  southern (0.79)\n",
      "\n",
      "Topic 07\n",
      "  security (5.87)\n",
      "  council (5.55)\n",
      "  permanent (1.41)\n",
      "  reform (1.37)\n",
      "  peace (1.37)\n",
      "  resolution (0.99)\n",
      "  members (0.87)\n",
      "  membership (0.73)\n",
      "\n",
      "Topic 08\n",
      "  people (1.32)\n",
      "  peace (1.27)\n",
      "  east (1.24)\n",
      "  middle (1.13)\n",
      "  palestinian (1.12)\n",
      "  israel (0.97)\n",
      "  arab (0.81)\n",
      "  region (0.69)\n",
      "\n",
      "Topic 09\n",
      "  development (4.40)\n",
      "  sustainable (1.17)\n",
      "  economic (1.11)\n",
      "  social (0.99)\n",
      "  goals (0.91)\n",
      "  agenda (0.73)\n",
      "  global (0.70)\n",
      "  millennium (0.70)\n"
     ]
    }
   ],
   "source": [
    "# display topics for paragraph model, set top words = 8 \n",
    "# change to para vectorizer \n",
    "display_topics(nmf_para_model, tfidf_para_vectorizer.get_feature_names(),\n",
    "              top_words=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fd2972",
   "metadata": {},
   "source": [
    "* We see some sharper dropping in topics E.G. topic 5 seems to resolutely be about human rights \n",
    "* Most regions have dropped out, except in those prevalent due to extra-ordinary events like israel/palestine/middle-east"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "020e1820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0 = 13.06%\n",
      "Topic 1 = 10.13%\n",
      "Topic 2 = 10.24%\n",
      "Topic 3 = 14.04%\n",
      "Topic 4 = 6.66%\n",
      "Topic 5 = 7.01%\n",
      "Topic 6 = 8.69%\n",
      "Topic 7 = 8.25%\n",
      "Topic 8 = 11.31%\n",
      "Topic 9 = 10.61%\n"
     ]
    }
   ],
   "source": [
    "# visualise what % of documents could be assigned mainly to each topic \n",
    "for i, val in enumerate(W_para_matrix.sum(axis=0) / W_para_matrix.sum() * 100.0 ):\n",
    "    print(\"Topic {} = {:.2f}%\".format(i, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01467aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a1078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a300ee2",
   "metadata": {},
   "source": [
    "## Singular value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31520887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2da061",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68faa191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d92a77d",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8ba70553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0bfe2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will just use the paragraphs version from here \n",
    "count_para_vectorizer = CountVectorizer(stop_words=stopwords, min_df=5,\n",
    "                        max_df=0.7)\n",
    "\n",
    "# fit to the paragraph data text from paragraph_df DF \n",
    "count_para_vectors = count_para_vectorizer.fit_transform(paragraph_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "73f32845",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_para_model = LatentDirichletAllocation(n_components = 10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ec9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "15dd2b32",
   "metadata": {},
   "source": [
    "* Very long runtime warning... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "38ded3f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;31m# calculate final perplexity value on train set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m         doc_topics_distr, _ = self._e_step(X, cal_sstats=False,\n\u001b[0m\u001b[0;32m    604\u001b[0m                                            \u001b[0mrandom_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m                                            parallel=parallel)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[1;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[0;32m    401\u001b[0m             parallel = Parallel(n_jobs=n_jobs, verbose=max(0,\n\u001b[0;32m    402\u001b[0m                                                            self.verbose - 1))\n\u001b[1;32m--> 403\u001b[1;33m         results = parallel(\n\u001b[0m\u001b[0;32m    404\u001b[0m             delayed(_update_doc_distribution)(X[idx_slice, :],\n\u001b[0;32m    405\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp_dirichlet_component_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[1;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             doc_topic_d = (exp_doc_topic_d *\n\u001b[1;32m--> 117\u001b[1;33m                            np.dot(cnts / norm_phi, exp_topic_word_d.T))\n\u001b[0m\u001b[0;32m    118\u001b[0m             \u001b[1;31m# Note: adds doc_topic_prior to doc_topic_d, in-place.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             _dirichlet_expectation_1d(doc_topic_d, doc_topic_prior,\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "W_lda_para_matrix = lda_para_model.fit_transform(count_para_vectors)\n",
    "H_lda_para_matrix = lda_para_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154871b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b93a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise \n",
    "display_topics(lda_para_model, count_para_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f24f3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a2b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921ae1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c635998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specialised LDA visualisation with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166ec234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1af5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb2dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec166b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455d61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b24a8b41",
   "metadata": {},
   "source": [
    "## Topic distribution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc39c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089f636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8338e931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41512beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75ee83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7419c46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4a3234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d56e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a11a89",
   "metadata": {},
   "source": [
    "# Nonnegative Matrix Factorisation (NMF)\n",
    "* Re-try with bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c780bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6056a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe0114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eafcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9210e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
